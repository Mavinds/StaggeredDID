{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e7048ea-7824-4935-9a9e-aaefbbbcf487",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from time import sleep\n",
    "import os\n",
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "import time\n",
    "import numpy as np\n",
    "from matplotlib.colors import TwoSlopeNorm, Normalize\n",
    "from matplotlib.cm import ScalarMappable\n",
    "import matplotlib.colors as mcolors\n",
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import pickle\n",
    "from collections import Counter\n",
    "from geopy.distance import geodesic"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e1d4af70-4423-4e23-85bb-d562a1c4707f",
   "metadata": {},
   "source": [
    "## Load POI data that are located within a 400 m radius of any EVCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcba8396-d8b8-4397-9a5e-d0be7f901223",
   "metadata": {},
   "outputs": [],
   "source": [
    "relativechange400mfinal = pd.read_csv('Sample_TotalPOIsData_within400m.csv')\n",
    "relativechange400mfinal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b1405ea-84ee-47fe-85f7-4809cb97ce79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_pois_by_city_and_group(df):\n",
    "    city_group_dfs = {}\n",
    "\n",
    "    grouped = df.groupby(['city', 'group'])\n",
    "\n",
    "    for (city, grp), group_df in grouped:\n",
    "        if not group_df.empty:\n",
    "            key = f\"{city}_{grp}\"\n",
    "\n",
    "            city_group_dfs[key] = group_df[['city', 'group', 'apiId', 'avg_pre_open', 'avg_post_open', 'Zscore', 'station_name', 'open_date', 'poi_zipcode']]\n",
    "\n",
    "    return city_group_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64bc6171-197b-40db-b6d4-1aced8b1fcb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "city_grouped_pois = filter_pois_by_city_and_group(relativechange400mfinal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76785a7-d17c-40c8-b897-3ad4644c683d",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_tables = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2500c2ea-ba5e-4a87-a436-2ac740fd4a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, df in city_grouped_pois.items():\n",
    "    if not df.empty:\n",
    "        if key not in final_tables:\n",
    "            final_tables[key] = df\n",
    "        else:\n",
    "            final_tables[key] = pd.concat([final_tables[key], df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251044f4-ff4e-4193-b18a-917688f2c56d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for key, df in final_tables.items():\n",
    "    print(f\"DataFrame for {key}:\")\n",
    "    print(df)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d669c48f-3c0b-4b87-90b5-ec529b4bb756",
   "metadata": {},
   "source": [
    "## Selection of potential control candidate POI group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d0856b-354c-4f40-b65c-77ddd295dafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_pois_with_different_station_name(final_tables):\n",
    "    poi_results = []\n",
    "\n",
    "    for key, df in final_tables.items():\n",
    "        df['open_date'] = pd.to_datetime(df['open_date'])\n",
    "\n",
    "        for i, poi_row in df.iterrows():\n",
    "            original_poi_id = poi_row['apiId']\n",
    "            original_city = poi_row['city']\n",
    "            original_group = poi_row['group']\n",
    "            original_station_name = poi_row['station_name'].strip().lower()  \n",
    "            original_open_date = poi_row['open_date']\n",
    "            original_avg_pre_open = poi_row['avg_pre_open']\n",
    "            original_avg_post_open = poi_row['avg_post_open']\n",
    "            original_Zscore_change = poi_row['Zscore']\n",
    "\n",
    "            similar_pois = df[\n",
    "                (df['apiId'] != original_poi_id) &  # Exclude the original POI\n",
    "                (df['station_name'].str.strip().str.lower() != original_station_name) &  \n",
    "                (df['open_date'] >= original_open_date + pd.DateOffset(months=3))  \n",
    "            ]\n",
    "\n",
    "            if not similar_pois.empty:\n",
    "                similar_pois = similar_pois.drop_duplicates(subset=['apiId'])\n",
    "\n",
    "                # Append the results with the original POI and its corresponding similar POIs\n",
    "                poi_results.append({\n",
    "                    'original_poi_id': original_poi_id,\n",
    "                    'original_city': original_city,\n",
    "                    'original_group': original_group,\n",
    "                    'original_station_name': poi_row['station_name'],  \n",
    "                    'original_open_date': original_open_date,\n",
    "                    'original_avg_pre_open': original_avg_pre_open,\n",
    "                    'original_avg_post_open': original_avg_post_open,\n",
    "                    'original_Zscore_change': original_Zscore_change,\n",
    "                    'similar_pois': similar_pois[[\n",
    "                        'apiId', 'poi_zipcode', 'group', 'station_name', 'open_date', \n",
    "                        'avg_pre_open', 'avg_post_open', 'Zscore', 'city'\n",
    "                    ]].to_dict(orient='records')  # Convert the similar POIs to a list of dictionaries\n",
    "                })\n",
    "\n",
    "    return poi_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5207c3-d5ae-4f5d-9a12-35a1fbe42788",
   "metadata": {},
   "outputs": [],
   "source": [
    "poi_results = find_pois_with_different_station_name(final_tables)\n",
    "poi_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2908b63e-8410-421d-b142-825eb6e8d063",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_filename = 'poi_results.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd93674-6a32-499c-92d9-d14087fdf324",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(pickle_filename, 'wb') as file:\n",
    "    pickle.dump(poi_results, file)\n",
    "print(f\"Results have been saved to {pickle_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22558ad7-08b2-41da-aab9-6cb1efd529fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for result in poi_results:\n",
    "    print(f\"Original POI ID: {result['original_poi_id']} (City: {result['original_city']}, Group: {result['original_group']}, Station: {result['original_station_name']}, Open Date: {result['original_open_date']}, Avg Pre Open: {result['original_avg_pre_open']}, Avg Post Open: {result['original_avg_post_open']}, Zscore Change: {result['original_Zscore_change']})\")\n",
    "    \n",
    "    print(\"Similar POIs:\")\n",
    "    for poi in result['similar_pois']:\n",
    "        print(f\"  - POI ID: {poi['apiId']}, City: {poi['city']}, Group: {poi['group']}, Station: {poi['station_name']}, Open Date: {poi['open_date']}, Avg Pre Open: {poi['avg_pre_open']}, Avg Post Open: {poi['avg_post_open']}, Zscore Change: {poi['Zscore']}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67889551-8ccc-4100-b178-df340f84e6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_groups = [result['original_group'] for result in poi_results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd871be7-8dbc-49a3-92ec-10abbfa41da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_counts = Counter(original_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe480f3a-59ee-4768-af4c-a611ed9679cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Original POI Groups and their counts:\")\n",
    "for group, count in group_counts.items():\n",
    "    print(f\"Group: {group}, Count: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5113e3a-f38e-4d20-a9d1-f00a05d3cda6",
   "metadata": {},
   "outputs": [],
   "source": [
    "poi_dataframes = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8d2c81-1ecc-4751-9038-14c3fd6d6419",
   "metadata": {},
   "outputs": [],
   "source": [
    "for result in poi_results:\n",
    "    # Extract the original POI information\n",
    "    original_poi_id = result['original_poi_id']\n",
    "    original_open_date = result['original_open_date']\n",
    "    original_station_name = result['original_station_name']\n",
    "    original_city = result['original_city']  \n",
    "    original_group = result['original_group']  \n",
    "\n",
    "    # Calculate the 3 months before and after the original open date\n",
    "    three_months_before = original_open_date - pd.DateOffset(months=3)\n",
    "    three_months_after = original_open_date + pd.DateOffset(months=3)\n",
    "\n",
    "    similar_pois_with_dates = []\n",
    "\n",
    "    # Loop through similar POIs\n",
    "    for poi in result['similar_pois']:\n",
    "        similar_poi_info = {\n",
    "            'POI ID': poi['apiId'],\n",
    "            'City': poi['city'],  \n",
    "            'Group': poi['group'],  \n",
    "            'Station': poi['station_name'],\n",
    "            'Open Date': poi['open_date'],\n",
    "            'Avg Pre Open': poi['avg_pre_open'],\n",
    "            'Avg Post Open': poi['avg_post_open'],\n",
    "            'Zscore Change': poi['Zscore'],\n",
    "            'Original POI Open Date': original_open_date,\n",
    "            'Original Station Name': original_station_name,\n",
    "            'Original POI City': original_city, \n",
    "            'Original POI Group': original_group,  \n",
    "            '3 Months Before Original POI Open Date': three_months_before,\n",
    "            '3 Months After Original POI Open Date': three_months_after\n",
    "        }\n",
    "\n",
    "        similar_pois_with_dates.append(similar_poi_info)\n",
    "\n",
    "    df = pd.DataFrame(similar_pois_with_dates)\n",
    "\n",
    "    poi_dataframes[original_poi_id] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b45f37-8a05-43b5-b12e-63e6338fa541",
   "metadata": {},
   "outputs": [],
   "source": [
    "for poi_id, df in poi_dataframes.items():\n",
    "    print(f\"DataFrame for Original POI ID {poi_id}:\")\n",
    "    print(df)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9928341d-9a8f-4f58-9d6d-50e9afc6c141",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae9c664-919e-47f5-be95-832eb8535be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load daily visits dataframe\n",
    "final_places_visits = pd.read_csv(\"DailyvisitsbyPOI.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d638973-f4c4-4b1e-84fc-d71d36a90dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_places_visits['Date'] = pd.to_datetime(final_places_visits['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243faf7b-163c-467a-87db-d3e07f2541d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool, cpu_count\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497df301-5d3b-428b-afb7-2184440c6ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_poi_batches(poi_results, batch_size=500, output_file='poi_dataframes_with_means.pkl3'):\n",
    "    with open(output_file, 'wb') as file:\n",
    "        poi_dataframes_with_means = {}\n",
    "\n",
    "        for batch_start in range(0, len(poi_results), batch_size):\n",
    "            batch = poi_results[batch_start:batch_start + batch_size]\n",
    "            \n",
    "            for result in batch:\n",
    "                original_poi_id = result['original_poi_id']\n",
    "                original_open_date = result['original_open_date']\n",
    "                original_station_name = result['original_station_name']\n",
    "                original_city = result['original_city']\n",
    "                \n",
    "                three_months_before = original_open_date - pd.DateOffset(months=3)\n",
    "                six_months_before = original_open_date - pd.DateOffset(months=6)\n",
    "                three_months_after = original_open_date + pd.DateOffset(months=3)\n",
    "                \n",
    "                similar_pois_with_dates_list = []\n",
    "                \n",
    "                original_group = final_places_visits.loc[final_places_visits['apiId'] == original_poi_id]\n",
    "\n",
    "                original_pre_pre_open_data = original_group[(original_group['Date'] >= six_months_before) & (original_group['Date'] < three_months_before)]\n",
    "                original_pre_open_data = original_group[(original_group['Date'] >= three_months_before) & (original_group['Date'] < original_open_date)]\n",
    "                original_post_open_data = original_group[(original_group['Date'] > original_open_date) & (original_group['Date'] <= three_months_after)]\n",
    "\n",
    "                original_avg_pre_pre_open = original_pre_pre_open_data['Visits'].mean() if not original_pre_pre_open_data.empty else None\n",
    "                original_avg_pre_open = original_pre_open_data['Visits'].mean() if not original_pre_open_data.empty else None\n",
    "                original_avg_post_open = original_post_open_data['Visits'].mean() if not original_post_open_data.empty else None\n",
    "                \n",
    "                for poi in result['similar_pois']:\n",
    "                    similar_group = final_places_visits.loc[final_places_visits['apiId'] == poi['apiId']]\n",
    "\n",
    "                    similar_pre_pre_open_data = similar_group[(similar_group['Date'] >= six_months_before) & (similar_group['Date'] < three_months_before)]\n",
    "                    similar_pre_open_data = similar_group[(similar_group['Date'] >= three_months_before) & (similar_group['Date'] < original_open_date)]\n",
    "                    similar_post_open_data = similar_group[(similar_group['Date'] > original_open_date) & (similar_group['Date'] <= three_months_after)]\n",
    "\n",
    "                    similar_avg_pre_pre_open = similar_pre_pre_open_data['Visits'].mean() if not similar_pre_pre_open_data.empty else None\n",
    "                    similar_avg_pre_open = similar_pre_open_data['Visits'].mean() if not similar_pre_open_data.empty else None\n",
    "                    similar_avg_post_open = similar_post_open_data['Visits'].mean() if not similar_post_open_data.empty else None\n",
    "\n",
    "                    similar_pois_with_dates_list.append({\n",
    "                        'POI ID': poi['apiId'],\n",
    "                        'Zip Code': poi['poi_zipcode'],\n",
    "                        'Group': poi['group'],\n",
    "                        'Station': poi['station_name'],\n",
    "                        'Open Date': poi['open_date'],\n",
    "                        'City': poi['city'],\n",
    "                        'Avg Pre Pre Open': similar_avg_pre_pre_open,\n",
    "                        'Avg Pre Open': similar_avg_pre_open,\n",
    "                        'Avg Post Open': similar_avg_post_open,\n",
    "                        'Original POI Open Date': original_open_date,\n",
    "                        'Original Station Name': original_station_name,\n",
    "                        'Original City': original_city,\n",
    "                        '6 Months Before Original POI Open Date': six_months_before,\n",
    "                        '3 Months Before Original POI Open Date': three_months_before,\n",
    "                        '3 Months After Original POI Open Date': three_months_after\n",
    "                    })\n",
    "                \n",
    "                poi_dataframes_with_means[original_poi_id] = {\n",
    "                    'similar_pois_data': similar_pois_with_dates_list,  # Store the list of similar POIs with calculated data\n",
    "                    'original_avg_pre_pre_open': original_avg_pre_pre_open,\n",
    "                    'original_avg_pre_open': original_avg_pre_open,\n",
    "                    'original_avg_post_open': original_avg_post_open\n",
    "                }\n",
    "            \n",
    "            pickle.dump(poi_dataframes_with_means, file)\n",
    "            print(f'Batch {batch_start // batch_size + 1} processed and saved.')\n",
    "            \n",
    "            poi_dataframes_with_means.clear()\n",
    "\n",
    "process_poi_batches(poi_results, batch_size=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce28883c-35b0-4f5f-b4f8-f335b94ba466",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pickle_data(file_path):\n",
    "    \"\"\"Load and combine batch data from the pickle file into a DataFrame.\"\"\"\n",
    "    all_data = []\n",
    "    \n",
    "    with open(file_path, 'rb') as file:\n",
    "        while True:\n",
    "            try:\n",
    "                batch_data = pickle.load(file)\n",
    "                all_data.append(batch_data)\n",
    "            except EOFError:\n",
    "                break\n",
    "\n",
    "    return all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83173db2-1bc9-4f13-8ccf-f27964b3ba89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataframe_from_poi_data(all_data):\n",
    "    \"\"\"Convert the loaded data into a DataFrame with unique pairs.\"\"\"\n",
    "    rows = []\n",
    "    processed_pairs = set()  \n",
    "\n",
    "    for batch_data in all_data:\n",
    "        for original_poi_id, poi_info in batch_data.items():\n",
    "            for similar_poi in poi_info['similar_pois_data']:\n",
    "                similar_poi_id = similar_poi['POI ID']\n",
    "                \n",
    "                if (original_poi_id, similar_poi_id) in processed_pairs:\n",
    "                    continue\n",
    "\n",
    "                processed_pairs.add((original_poi_id, similar_poi_id))\n",
    "                rows.append({\n",
    "                    'Original POI ID': original_poi_id,\n",
    "                    'Original Avg Pre Pre Open': poi_info['original_avg_pre_pre_open'],\n",
    "                    'Original Avg Pre Open': poi_info['original_avg_pre_open'],\n",
    "                    'Original Avg Post Open': poi_info['original_avg_post_open'],\n",
    "                    **similar_poi  \n",
    "                })\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    return df\n",
    "\n",
    "file_path = 'poi_dataframes_with_means.pkl3'\n",
    "all_data = load_pickle_data(file_path)\n",
    "\n",
    "poi_df = create_dataframe_from_poi_data(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6632813d-6849-474f-8ee1-0dedf94f3c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "poi_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765b3d2a-dd72-46be-be07-d9a6dc0b32c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "poi_df.to_csv(\"Citylevelmatchedsynthetic.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ecb10ef-e629-4cf3-bcb2-9d0f1f17ff10",
   "metadata": {},
   "outputs": [],
   "source": [
    "size_thresholds = [0, 50, 100, 200, 500, 1000, 2500, 5000, 10000, 25000, np.inf]\n",
    "size_labels = ['0-50', '50-100', '100-200', '200-500', '500-1000', '1000-2500','2500-5000', '5000-10000', '10000-25000', '25000+']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c158d58-65b0-4917-8e13-892965eab935",
   "metadata": {},
   "outputs": [],
   "source": [
    "poi_df['size_group'] = pd.cut(poi_df['Original Avg Pre Open'], bins=size_thresholds, labels=size_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "405809b6-0af4-497f-8d74-957138b4e4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_by_size_group(df):\n",
    "    filtered_rows = []\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        size_range = row['size_group']\n",
    "        \n",
    "        if isinstance(size_range, str):\n",
    "            try:\n",
    "                if '-' in size_range:\n",
    "                    min_size, max_size = [int(x) for x in size_range.split('-')]\n",
    "                else:\n",
    "                    min_size, max_size = int(size_range[:-1]), float('inf')\n",
    "            except ValueError:\n",
    "                continue  \n",
    "        else:\n",
    "            continue \n",
    "        \n",
    "        if min_size <= row['Avg Pre Open'] <= max_size:\n",
    "            filtered_rows.append(row)\n",
    "    \n",
    "    filtered_df = pd.DataFrame(filtered_rows)\n",
    "    \n",
    "    filtered_df = filtered_df.drop_duplicates(subset=['Original POI ID', 'POI ID'], keep='first')\n",
    "    \n",
    "    return filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83726f66-1492-4821-a5d8-f3fa2a2f6ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_poi_df2 = filter_by_size_group(poi_df)\n",
    "filtered_poi_df2.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "503b0e3d-7514-451f-8d81-a881e64b166d",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_poi_df2 = filtered_poi_df2.drop_duplicates(subset=['Original POI ID', 'POI ID'], keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aaa5878-9b3a-4cf1-b11e-da20fcb3baf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_poi_df2.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06649cb-dd2d-455b-8a4f-9040ff8a30d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_poi_df2.to_csv(\"Citylevelmatchedsynthetic2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da986bfc-08cc-4172-881a-6835fccddc67",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_poi_df2['Original POI Open Date'] = pd.to_datetime(filtered_poi_df2['Original POI Open Date'])\n",
    "filtered_poi_df2['Original POI Open Year'] = filtered_poi_df2['Original POI Open Date'].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4b76b2-e768-40e8-99b8-4f439dbeea59",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_poi_df2['DiD1'] = filtered_poi_df2['Original Avg Post Open'] - filtered_poi_df2['Original Avg Pre Open']\n",
    "filtered_poi_df2['DiD2'] = filtered_poi_df2['Avg Post Open'] - filtered_poi_df2['Avg Pre Open']\n",
    "filtered_poi_df2['DiD'] = filtered_poi_df2['DiD1'] - filtered_poi_df2['DiD2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8159895-8a61-4f79-8f37-41e6ed3288ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_poi_df2['DiD3'] = filtered_poi_df2['Original Avg Pre Open'] - filtered_poi_df2['Original Avg Pre Pre Open']\n",
    "filtered_poi_df2['DiD4'] = filtered_poi_df2['Avg Pre Open'] - filtered_poi_df2['Avg Pre Pre Open']\n",
    "filtered_poi_df2['DiD5'] = filtered_poi_df2['DiD3'] - filtered_poi_df2['DiD4']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a01042a-eb8d-47f2-883f-185cfdda4db7",
   "metadata": {},
   "source": [
    "## Approach to find the best match using pre-treatment difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0c93fe-ee7e-4a40-a2df-bae4b7c132f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_match(df):\n",
    "    matched_rows = []\n",
    "    all_similar_pois = {}\n",
    "    used_similar_pois = set()  \n",
    "    matched_pois = set()      \n",
    "\n",
    "    for original_poi_id in df['Original POI ID'].unique():\n",
    "        subset = df[df['Original POI ID'] == original_poi_id]\n",
    "        \n",
    "        if not subset.empty:\n",
    "            all_similar_pois[original_poi_id] = set(subset['POI ID'])\n",
    "            subset['difference'] = abs(subset['DiD3'] - subset['DiD4'])\n",
    "            best_match_index = subset['difference'].idxmin()\n",
    "            best_match = subset.loc[best_match_index]\n",
    "            matched_rows.append(best_match)\n",
    "            matched_pois.add(original_poi_id)  \n",
    "            used_similar_pois.add(best_match['POI ID'])  \n",
    "    \n",
    "    matched_df = pd.DataFrame(matched_rows)\n",
    "    \n",
    "    not_matched_similar_pois = []\n",
    "    \n",
    "    for original_poi_id, similar_pois in all_similar_pois.items():\n",
    "        matched_similar_pois = used_similar_pois.intersection(similar_pois)\n",
    "        dropped_similar_pois = similar_pois - matched_similar_pois\n",
    "        if dropped_similar_pois:\n",
    "            not_matched_similar_pois.append({\n",
    "                'Original POI ID': original_poi_id,\n",
    "                'Dropped Similar POIs': list(dropped_similar_pois)\n",
    "            })\n",
    "    \n",
    "    not_matched_similar_df = pd.DataFrame(not_matched_similar_pois)\n",
    "    \n",
    "    num_unique_original_pois = matched_df['Original POI ID'].nunique()\n",
    "    print(f'Number of unique Original POI IDs in the matched dataframe: {num_unique_original_pois}')\n",
    "    print(f'Number of similar POIs dropped: {not_matched_similar_df.shape[0]}')\n",
    "    \n",
    "    return matched_df, not_matched_similar_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85238a37-2e57-4b7e-80f1-a2b2afeeb40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_df, not_matched_similar_df = find_best_match(filtered_poi_df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ec16d4-e369-4a55-aeeb-e246b1df26f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df2=matched_df\n",
    "filtered_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa07bd3-5f25-4d6f-9117-48a1a1791c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df2.to_csv(\"CityMatchedPOIsCleanedsynthetic.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3900f5c1-8300-433f-a1ec-ee999f8396cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df2 = pd.read_csv('CityMatchedPOIsCleanedsynthetic.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd0ef260-3959-4642-afcc-09fa4b3bbe86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_distance(row):\n",
    "    orig_coords = (row['orig_latitude'], row['orig_longitude'])\n",
    "    sim_coords = (row['ev_latitude'], row['ev_longitude'])\n",
    "    \n",
    "    return geodesic(orig_coords, sim_coords).meters\n",
    "\n",
    "filtered_df2['Distance(m)'] = filtered_df2.apply(calculate_distance, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00259bf3-f865-4b30-8309-215583808415",
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = [0, 100, 200, 300, np.inf]\n",
    "labels = ['0-100m', '100-200m', '200-300m', '300-400m']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9107b8-d787-488f-8576-c36417fa929a",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df2['distance_group'] = pd.cut(filtered_df2['Distance(m)'], bins=thresholds, labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c9a289-afab-4963-ad90-8b66ea16dd90",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df2.to_csv(\"CityMatchedPOIsCleanedforDID.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4764140-b9f1-4369-8ee0-13cf1a317869",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
